# app.py
from datetime import datetime, timezone
import os, glob, pandas as pd, streamlit as st
import pathlib
import git
import difflib

# è¨€èªåˆ¥UIãƒ†ã‚­ã‚¹ãƒˆ
UI_STR = {
    "ja": {
        "tags": "ã‚¿ã‚°",
        "tag_rule": "ã‚¿ã‚°ã®æ¡ä»¶",
        "tag_rule_opts": {"AND": "ã™ã¹ã¦å«ã‚€ (AND)", "OR": "ã„ãšã‚Œã‹å«ã‚€ (OR)"},
        "envs": "ç’°å¢ƒ",
        "env_rule": "ç’°å¢ƒã®æ¡ä»¶",
        "env_rule_opts": {"AND": "ã™ã¹ã¦å«ã‚€ (AND)", "OR": "ã„ãšã‚Œã‹å«ã‚€ (OR)"},
        "apply_filters": "ãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨",
        "diff_toggle": "å·®åˆ†ã‚’å¼·èª¿",
        "diff_slow_notice": "Diff ã‚’å¼·èª¿ã™ã‚‹ã¨è¡¨ç¤ºã«æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚",
        "info_select_filters": "å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ•ã‚£ãƒ«ã‚¿ã‚’é¸ã‚“ã§ã€Œãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚",
        "results": "çµæœ â€“ {n} ä»¶",
        "dup_warning": "é‡è¤‡ã—ãŸ MishearID ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:",
        "help_title": "ä½¿ã„æ–¹",
        "help_usage": (
            "- ã‚¿ã‚°/ç’°å¢ƒã‚’é¸ã³ã€AND/OR ãƒ«ãƒ¼ãƒ«ã‚’è¨­å®šã—ã¾ã™ï¼ˆæœªé¸æŠã¯å…¨ä»¶ãƒ’ãƒƒãƒˆï¼‰ã€‚\n"
            "- ã€ãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨ã€ã‚’æŠ¼ã—ã¦çµæœã‚’æ›´æ–°ã—ã¾ã™ã€‚\n"
            "- Results ã§ã¯ã€å·®åˆ†ã‚’å¼·èª¿ã€ã®ãƒˆã‚°ãƒ«ã¨ã€åˆ—ã®å¹…ã€ãƒ©ã‚¸ã‚ªï¼ˆsmall/medium/large, Src/Tgt å…±é€šï¼‰ã‚’å¤‰æ›´ã§ãã¾ã™ã€‚\n"
            "- å·®åˆ†å¼·èª¿ã¯ Src/Tgt ã®ç½®æ›éƒ¨åˆ†ã®ã¿ã‚’ **** ã§å¼·èª¿ã—ã¾ã™ï¼ˆä¸€éƒ¨ç’°å¢ƒã§è¡¨ç¤ºãŒé…ããªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ãŒã€è¨ˆç®—ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã¾ã™ï¼‰ã€‚\n"
            "- è¡¨ã§ã¯ `Src`=è©±ã—æ‰‹ã®æ„å›³ã€`Tgt`=èãæ‰‹ã®è§£é‡ˆ ã‚’ç¤ºã—ã¾ã™ã€‚"
        ),
    "src_width_label": "Srcåˆ—ã®å¹…",
    "tgt_width_label": "Tgtåˆ—ã®å¹…",
    "width_label": "åˆ—ã®å¹…",
        "width_help": "small / medium / large ã‚’é¸æŠ",
        "stats_dir": "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåˆ¥ä»¶æ•°",
        "stats_total": "åˆè¨ˆ",
        "stats_total_metric": "ç·ä»¶æ•°",
        "progress_header": "Corpus è¡Œæ•°ã®æ¨ç§»",
        "src_tgt_desc": "src ã¯è©±ã—æ‰‹ãŒæ„å›³ã—ãŸè¨€è‘‰ã€tgt ã¯èãæ‰‹ã®è§£é‡ˆã§ã™ã€‚",
    },
    "en": {
        "tags": "Tags",
        "tag_rule": "Tag rule",
        "tag_rule_opts": {"AND": "Must include all (AND)", "OR": "Include any (OR)"},
        "envs": "Environments",
        "env_rule": "Env rule",
        "env_rule_opts": {"AND": "Must include all (AND)", "OR": "Include any (OR)"},
        "apply_filters": "Apply filters",
        "diff_toggle": "Emphasize diff",
        "diff_slow_notice": "Enabling diff emphasis may slow down rendering.",
        "info_select_filters": "Select filters on the left and press Apply filters.",
        "results": "Results â€“ {n} rows",
        "dup_warning": "Duplicate MishearIDs found:",
        "help_title": "How to use",
        "help_usage": (
            "- Pick Tags and Environments, then set the AND/OR rule (leaving them empty matches all rows).\n"
            "- Press Apply filters to update the results.\n"
            "- In Results you can toggle Emphasize diff and choose Column width (small/medium/large; common for Src/Tgt).\n"
            "- Diff highlights only replaced segments in Src/Tgt. It may be slower on big tables, but the computation is cached.\n"
            "- In the table, `Src` is the intended utterance; `Tgt` is the listenerâ€™s interpretation."
        ),
    "src_width_label": "Src width",
    "tgt_width_label": "Tgt width",
    "width_label": "Column width",
        "width_help": "Choose small / medium / large",
        "stats_dir": "Counts by directory",
        "stats_total": "Total",
        "stats_total_metric": "Total rows",
        "progress_header": "Corpus row count over time",
        "src_tgt_desc": "src is the intended word/utterance; tgt is the listener's interpretation.",
    },
}

from scripts.asa2025.extract_word_pairs import extract_word_mishear_pairs

def extract_dir(path_str: str) -> str:
    """
    data/mishearing/<DIR_NAME>/file.csv ã‹ã‚‰ <DIR_NAME> ã‚’å–ã‚Šå‡ºã™ã€‚
    æƒ³å®šå¤–ã®å½¢å¼ãªã‚‰ç©ºæ–‡å­—ã‚’è¿”ã™ã€‚
    """
    try:
        parts = pathlib.Path(path_str).parts
        # parts = ('data', 'mishearing', '<DIR_NAME>', 'YYYY-MM-DD_xxx.csv')
        return parts[2] if len(parts) >= 3 else ""
    except Exception:
        return ""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ I/O helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
@st.cache_data(show_spinner=False)
def load_csv_tree(*args, **kwargs):
    return _load_csv_tree(*args, **kwargs)

def _load_csv_tree(root: str, *, exclude: str | None = None) -> pd.DataFrame:
    pat = os.path.join(root, "**/*.csv")
    files = [f for f in glob.glob(pat, recursive=True) if not exclude or exclude not in f]
    dataframes = []
    for f in files:
        # å•é¡ŒãŒã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã¯ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å‡ºåŠ›
        try:
            df = pd.read_csv(f)
            df["path"] = f  # Add a column with the file path
            dataframes.append(df)
        except:
            st.error(f"Error reading {f}. Please check the file format.")
            st.stop()
    return pd.concat(dataframes, ignore_index=True)

@st.cache_data(show_spinner=False)
def load_translation(root: str) -> pd.DataFrame:
    return pd.read_csv(os.path.join(root, "translation.csv"))

def id_to_label(ids, trans_df, lang):
    mapping = (
        trans_df.loc[trans_df["Lang"] == lang]
        .set_index(trans_df.columns[0])["Label"]
        .to_dict()
    )
    return [mapping.get(i, i) for i in ids]

def label_to_id(labels, trans_df, lang):
    mapping = (
        trans_df.loc[trans_df["Lang"] == lang]
        .set_index("Label")[trans_df.columns[0]]
        .to_dict()
    )
    return [mapping[lbl] for lbl in labels if lbl in mapping]

def make_mask(link_df, key_col, picked_ids, logic_key) -> set[str]:
    """
    logic_key: "AND" or "OR"
    """
    if not picked_ids:
        return set(link_df["MishearID"])
    if logic_key == "AND":
        ok = link_df.groupby("MishearID")[key_col].apply(lambda s: set(picked_ids).issubset(s))
        return set(ok[ok].index)
    return set(link_df[link_df[key_col].isin(picked_ids)]["MishearID"])


@st.cache_resource(show_spinner=False)
def _mark_replace_only(src: str, tgt: str) -> tuple[str, str]:
    if pd.isna(src) or pd.isna(tgt):
        s0 = "" if pd.isna(src) else str(src).replace("\n", " â ")
        t0 = "" if pd.isna(tgt) else str(tgt).replace("\n", " â ")
        return s0, t0
    s, t = str(src), str(tgt)
    sm = difflib.SequenceMatcher(a=s, b=t)
    out_s, out_t = [], []
    for tag, i1, i2, j1, j2 in sm.get_opcodes():
        if tag == "equal":
            out_s.append(s[i1:i2])
            out_t.append(t[j1:j2])
        elif tag == "replace":
            out_s.append(f" **{s[i1:i2]}** ")
            out_t.append(f" **{t[j1:j2]}** ")
        elif tag == "delete":
            out_s.append(s[i1:i2])
        elif tag == "insert":
            out_t.append(t[j1:j2])
    return "".join(out_s).replace("\n", " â "), "".join(out_t).replace("\n", " â ")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Core application class â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
class MishearingApp:
    ROOT = "data"

    def __init__(self):
        tag_root = f"{self.ROOT}/tag"
        env_root = f"{self.ROOT}/environment"
        self.mishear_root = f"{self.ROOT}/mishearing"

        self.tag_trans = load_translation(tag_root)
        self.env_trans = load_translation(env_root)

        self.tag_link = load_csv_tree(tag_root, exclude="translation.csv")
        self.env_link = load_csv_tree(env_root, exclude="translation.csv")
        self.corpus   = load_csv_tree(self.mishear_root)

        # Pre-compute counts
        self.tag_counts = self.tag_link["TagID"].value_counts()
        self.env_counts = self.env_link["EnvID"].value_counts()

    @property
    def urls(self) -> set[str]:
        """
        Returns a dictionary of URLs for the tag and environment links.
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ã‚ãšã«å¸¸ã«æœ€æ–°ã®URLã®ã‚»ãƒƒãƒˆã‚’å–å¾—ã™ã‚‹ã€‚
        """
        return set(_load_csv_tree(self.mishear_root).URL)

    # ------------- UI ------------ #
    def form(self):
        lang_options = ["en", "ja", "zh", "ko"]
        lang_labels = {
            "en": "English",
            "ja": "æ—¥æœ¬èª",
            "zh": "ä¸­æ–‡ (Not implemented)",
            "ko": "í•œêµ­ì–´ (Not implemented)",
        }
        lang = st.radio(
            "Language",
            options=lang_options,
            format_func=lambda x: lang_labels[x],
            index=1,
            horizontal=True,
        )
        if lang in ("zh", "ko"):
            st.warning("This language is not supported yet. Displaying in English.")
            lang = "en"

        # ç¾åœ¨ã®è¨€èªã‚’å…±æœ‰
        st.session_state["lang"] = lang
        ui = UI_STR.get(lang, UI_STR["ja"])

        with st.form(key="filter_form"):
            # ä½¿ã„æ–¹ (ã‚¢ãƒ—ãƒªå†…ãƒ˜ãƒ«ãƒ—) ã‚’ãƒ•ã‚©ãƒ¼ãƒ å†…ã®å…ˆé ­ã«é…ç½®
            with st.expander(ui.get("help_title", ""), expanded=True):
                st.markdown(ui.get("help_usage", ""))
            # Tag "mishearing" ã¯é¸æŠè‚¢ã‹ã‚‰é™¤å¤–
            allowed_tag_ids = [tid for tid in self.tag_counts.index if str(tid) != "MISHEARING"]
            tag_lbls = id_to_label(allowed_tag_ids, self.tag_trans, lang)
            env_lbls = id_to_label(self.env_counts.index, self.env_trans, lang)

            picked_tags = st.multiselect(ui["tags"], tag_lbls)

            tag_logic_key = st.radio(
                ui["tag_rule"],
                options=["AND", "OR"],
                format_func=lambda k: ui["tag_rule_opts"][k],
                horizontal=True,
            )

            picked_envs = st.multiselect(ui["envs"], env_lbls)

            env_logic_key = st.radio(
                ui["env_rule"],
                options=["AND", "OR"],
                format_func=lambda k: ui["env_rule_opts"][k],
                horizontal=True,
            )

            # ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨ãƒœã‚¿ãƒ³ã®ã¿ï¼ˆå·®åˆ†/åˆ—å¹…ã¯çµæœã‚¨ãƒªã‚¢ã§æŒ‡å®šï¼‰
            submitted = st.form_submit_button(ui["apply_filters"])

        return submitted, lang, picked_tags, tag_logic_key, picked_envs, env_logic_key

    def run(self):
        submitted, lang, p_tag_lbl, tag_logic_key, p_env_lbl, env_logic_key = self.form()

        # ãƒ•ã‚£ãƒ«ã‚¿ã®çŠ¶æ…‹ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿æŒï¼ˆåˆå›ã¯é©ç”¨ãƒœã‚¿ãƒ³ãŒå¿…è¦ï¼‰
        if submitted:
            p_tag_ids = label_to_id(p_tag_lbl, self.tag_trans, lang)
            p_env_ids = label_to_id(p_env_lbl, self.env_trans, lang)
            st.session_state["filters"] = {
                "tag_ids": p_tag_ids,
                "env_ids": p_env_ids,
                "tag_logic": tag_logic_key,
                "env_logic": env_logic_key,
                "lang": lang,
            }

        filters = st.session_state.get("filters")
        if not filters:
            st.info(UI_STR.get(lang, UI_STR["ja"]) ["info_select_filters"])
            return

        # --- translate back to IDs (from stored filters) --- #
        p_tag_ids = filters["tag_ids"]
        p_env_ids = filters["env_ids"]
        keep_tag = make_mask(self.tag_link, "TagID", p_tag_ids, filters["tag_logic"])
        keep_env = make_mask(self.env_link, "EnvID", p_env_ids, filters["env_logic"])
        final_ids = keep_tag & keep_env

        # --- main pane --- #
        ui = UI_STR.get(st.session_state.get("lang", lang), UI_STR["ja"])
        st.header(ui["results"].format(n=len(final_ids)))
        # Show explanation of src/tgt
        if "src_tgt_desc" in ui:
            st.caption(ui["src_tgt_desc"])

        # çµæœã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è¡¨ç¤ºã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆå·®åˆ†ã¨åˆ—å¹…ï¼‰

        col_opt1, col_opt2 = st.columns([1, 2])
        with col_opt1:
            # st.toggle ãŒç„¡ã„ç’°å¢ƒã«é…æ…®
            _toggle = getattr(st, "toggle", st.checkbox)
            emphasize_diff = _toggle(
                ui["diff_toggle"],
                help=ui["diff_slow_notice"],
                key="emphasize_diff",
            )
        width_opts = ["small", "medium", "large"]
        with col_opt2:
            col_width = st.radio(
                ui.get("width_label", "Column width"),
                options=width_opts,
                index=1,
                horizontal=True,
                key="col_width",
            )

        result_df = self.corpus[self.corpus["MishearID"].isin(final_ids)].copy()

        # å¸¸ã« DataFrame ã‚’ä½¿ç”¨ã€‚Diff ON ã®å ´åˆã®ã¿ Src/Tgt ãƒ†ã‚­ã‚¹ãƒˆã« ** ã‚’åŸ‹ã‚è¾¼ã‚€
        src_width = col_width
        tgt_width = col_width
        if emphasize_diff:
            src_col, tgt_col = "Src", "Tgt"

            # å¤‰æ›ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’åæ˜ 
            marked_src = []
            marked_tgt = []
            for _, row in result_df[[src_col, tgt_col]].iterrows():
                s_mark, t_mark = _mark_replace_only(row[src_col], row[tgt_col])
                marked_src.append(s_mark)
                marked_tgt.append(t_mark)
            result_df[src_col] = marked_src
            result_df[tgt_col] = marked_tgt

            # Markdown ã¨ã—ã¦è§£é‡ˆã—ã¦ã‚‚ã‚‰ã†ï¼ˆã‚µãƒãƒ¼ãƒˆãŒç„¡ã„å ´åˆã¯è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            src_cfg = st.column_config.TextColumn(width=src_width, help="Src")
            tgt_cfg = st.column_config.TextColumn(width=tgt_width, help="Tgt")
            st.dataframe(
                result_df,
                hide_index=True,
                use_container_width=True,
                column_config={src_col: src_cfg, tgt_col: tgt_cfg},
            )
        else:
            # Diff OFF æ™‚ã‚‚ Src/Tgt ã®å¹…ã¨æŠ˜è¿”ã—ã‚’æŒ‡å®š
            cfg = {}
            cfg["Src"] = st.column_config.TextColumn(width=src_width, help="Src")
            cfg["Tgt"] = st.column_config.TextColumn(width=tgt_width, help="Tgt")
            st.dataframe(result_df, hide_index=True, use_container_width=True, column_config=cfg)

    def check(self):
        # MishearIDãŒ2ã¤ä»¥ä¸Šã®è¡Œã‚’æŠ½å‡º
        dup_ids = self.corpus["MishearID"].value_counts()
        dup_ids = dup_ids[dup_ids > 1].index.tolist()
        if dup_ids:
            dup_paths = self.corpus[self.corpus["MishearID"].isin(dup_ids)][["MishearID", "path"]]
            lang = st.session_state.get("lang", "ja")
            st.warning(UI_STR.get(lang, UI_STR["ja"])["dup_warning"])
            st.dataframe(dup_paths)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Bootstrap â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #

def main():
    st.title("Mishearing Corpus Viewer")
    MishearingApp().check()
    MishearingApp().run()

st.set_page_config(
    page_title="Mishearing Corpus",
    layout="wide",
    page_icon="ğŸ“‚",
)

main_tab, stats_tab, progress_tab, disclaimer_tab, extractor_tab = st.tabs(["Viewer", "Stats", "Progress", "Disclaimer", "Extractor"])

with main_tab:
    main()

with stats_tab:
    lang = st.session_state.get("lang", "ja")
    ui = UI_STR.get(lang, UI_STR["ja"])
    df = MishearingApp().corpus
    df["dir"] = df["path"].apply(extract_dir)
    counts = df["dir"].value_counts(dropna=False).reset_index()
    counts.columns = ["Directory", "Count"]
    total = len(df)

    # â”€â”€â”€ è¡¨ç¤º â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.subheader(ui["stats_dir"])
    st.dataframe(counts)

    st.subheader(ui["stats_total"])
    st.metric(label=ui["stats_total_metric"], value=total)


@st.cache_data(show_spinner="Git å±¥æ­´ã‚’è§£æä¸­ â€¦")
def build_history() -> pd.DataFrame:
    repo = git.Repo(pathlib.Path(__file__).resolve().parent)
    records = []

    # mishearing ã«å¤‰æ›´ãŒã‚ã£ãŸã‚³ãƒŸãƒƒãƒˆã‚’èµ°æŸ»
    for c in repo.iter_commits(paths="data/mishearing"):
        ts = datetime.fromtimestamp(c.committed_date, tz=timezone.utc)
        env_files, tag_files, mis_blobs = set(), set(), []

        # ãƒ„ãƒªãƒ¼ã‚’ä¸€åº¦ã ã‘èµ°æŸ»ã—ã¦ 3 ç¨®ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†
        for b in c.tree.traverse():
            p = b.path
            if p.endswith(".csv"):
                name = pathlib.Path(p).name  # ãƒ•ã‚¡ã‚¤ãƒ«åã®ã¿
                if p.startswith("data/environment/"):
                    env_files.add(name)
                elif p.startswith("data/tag/"):
                    tag_files.add(name)
                elif p.startswith("data/mishearing/"):
                    mis_blobs.append((name, b))  # å¾Œã§èª­ã‚€ã®ã§ blob ã‚‚ä¿æŒ

        # åŒå CSV ãŒä¸‰ç®‡æ‰€ã™ã¹ã¦ã«ã‚ã‚‹å ´åˆ(ãƒ‡ãƒ¼ã‚¿ã‚’é©åˆ‡ã«è¿½åŠ ã—ã¦ã„env, tagã‚’ç”Ÿæˆã—ãŸå ´åˆ)ã ã‘ã‚«ã‚¦ãƒ³ãƒˆ
        total = 0
        for name, blob in mis_blobs:
            if name in env_files and name in tag_files:
                rows = blob.data_stream.read().decode("utf-8", "ignore").splitlines()
                total += max(len(rows) - 1, 0)  # ãƒ˜ãƒƒãƒ€ãƒ¼ 1 è¡Œã‚’é™¤å¤–

        if total:  # è¡Œæ•° 0 ã¯é™¤å¤–
            records.append({"commit": c.hexsha[:7], "timestamp": ts, "rows": total})

    # DataFrame åŒ–ã¨æ—¥ä»˜è£œå®Œ
    df = pd.DataFrame(records).sort_values("timestamp")
    df["date"] = df["timestamp"].dt.normalize()

    daily = (
        df.groupby("date", as_index=False)
          .last()                                # åŒæ—¥ã®æœ€æ–°ã‚³ãƒŸãƒƒãƒˆã‚’æ¡ç”¨
          .set_index("date")
    )

    full_idx = pd.date_range(daily.index.min(), daily.index.max(), freq="D", tz="UTC")
    daily = (
        daily.reindex(full_idx)
             .ffill()                            # å‰å›å€¤ã§åŸ‹ã‚ã‚‹
    )
    return daily.reset_index(names="date")

with progress_tab:
    lang = st.session_state.get("lang", "ja")
    ui = UI_STR.get(lang, UI_STR["ja"])
    st.subheader(ui["progress_header"])
    daily = build_history()

    st.line_chart(daily.set_index("date")["rows"], height=300)
    st.dataframe(daily, height=250, hide_index=True)

with disclaimer_tab:
    # Language-aware disclaimer page
    lang = st.session_state.get("lang", "ja")
    if lang == "en":
        st.header("Disclaimer")
        st.subheader("Usage notes")
        st.markdown(
            "\n".join(
                [
                    "- This corpus is provided primarily for research and educational purposes.",
                    "- Listed URLs and external contents reflect the state at the time of collection and may have changed or been removed since then.",
                    "- Minor inconsistencies or errors may remain. Contributions and fixes are welcome â€” please use GitHub Issues.",
                ]
            )
        )
        st.subheader("Disclaimer of warranty and liability")
        st.markdown(
            "\n".join(
                [
                    "- The authors make no warranties regarding accuracy, completeness, or fitness for a particular purpose.",
                    "- The authors shall not be liable for any damages arising from the use of this corpus or viewer.",
                    "- Please comply with the terms of use and copyright laws of any referenced/linked sites when using the data.",
                ]
            )
        )
        st.subheader("Contact")
        st.markdown(
            "\n".join(
                [
                    "- For bug reports, improvement proposals, and questions, please open an Issue on GitHub.",
                    "- Issues: https://github.com/kishiyamat/mishearing-corpus/issues",
                ]
            )
        )
    else:
        st.header("å…è²¬äº‹é … / åˆ©ç”¨ä¸Šã®æ³¨æ„")
        st.subheader("åˆ©ç”¨ä¸Šã®æ³¨æ„")
        st.markdown(
            "\n".join(
                [
                    "- æœ¬ã‚³ãƒ¼ãƒ‘ã‚¹ã¯ä¸»ã«ç ”ç©¶ãƒ»æ•™è‚²ç›®çš„ã§å…¬é–‹ã—ã¦ã„ã¾ã™ã€‚",
                    "- è¨˜è¼‰ã•ã‚ŒãŸ URL ã‚„å¤–éƒ¨ã‚µã‚¤ãƒˆã®å†…å®¹ã¯åé›†æ™‚ç‚¹ã®ã‚‚ã®ã§ã‚ã‚Šã€ç¾åœ¨ã¯å¤‰æ›´ãƒ»å‰Šé™¤ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚",
                    "- è¡¨è¨˜ã‚†ã‚Œã‚„èª¤ã‚ŠãŒæ®‹ã£ã¦ã„ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ä¿®æ­£ã‚„æ”¹å–„ã®ææ¡ˆã¯ GitHub ã® Issue ã¸ãŠå¯„ã›ãã ã•ã„ã€‚",
                ]
            )
        )
        st.subheader("å…è²¬äº‹é …")
        st.markdown(
            "\n".join(
                [
                    "- æœ¬ã‚³ãƒ¼ãƒ‘ã‚¹ãŠã‚ˆã³ãƒ“ãƒ¥ãƒ¼ã‚¢ã®å†…å®¹ã«ã¤ã„ã¦ã€æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ãƒ»æœ‰ç”¨æ€§ç­‰ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚",
                    "- æœ¬ã‚³ãƒ¼ãƒ‘ã‚¹ã®åˆ©ç”¨ã«ã‚ˆã‚Šç”Ÿã˜ãŸã„ã‹ãªã‚‹æå®³ã«ã¤ã„ã¦ã‚‚ã€ä½œæˆè€…ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚",
                    "- å‚ç…§ãƒ»åé›†å¯¾è±¡ã‚µã‚¤ãƒˆã®åˆ©ç”¨è¦ç´„ãƒ»è‘—ä½œæ¨©æ³•ç­‰ã‚’éµå®ˆã®ã†ãˆã€é©åˆ‡ã«ã”åˆ©ç”¨ãã ã•ã„ã€‚",
                ]
            )
        )
        st.subheader("é€£çµ¡å…ˆ")
        st.markdown(
            "\n".join(
                [
                    "- ä¸å…·åˆå ±å‘Šã€æ”¹å–„ææ¡ˆã€è³ªå•ãªã©ã¯ GitHub ã® Issues ã«ã¦å—ã‘ä»˜ã‘ã¦ã„ã¾ã™ã€‚",
                    "- Issues: https://github.com/kishiyamat/mishearing-corpus/issues",
                ]
            )
        )

with extractor_tab:
    st.subheader("Extractor")
    st.markdown(
        """
æŠ½å‡ºå‡¦ç†ã¯ Streamlit ã‹ã‚‰åˆ‡ã‚Šé›¢ã•ã‚Œã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨ã—ã¦å®Ÿè¡Œã§ãã¾ã™ã€‚

æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ«ãƒ¼ãƒˆã§å®Ÿè¡Œã—ã¦ãã ã•ã„:

```bash
source .venv/bin/activate
python scripts/asa2025/extract_word_pairs.py
```

ã“ã‚Œã«ã‚ˆã‚Š `resource/extracted_word_pairs.csv` ãŒç”Ÿæˆ / ä¸Šæ›¸ãã•ã‚Œã¾ã™ã€‚
"""
    )